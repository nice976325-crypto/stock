# 开发环境配置
# Tomcat
server:
    tomcat:
        uri-encoding: UTF-8
    port: 18081
    servlet:
        context-path: /nolan

#name-node
hadoop.name-node: hdfs://localhost:9000
#hdfs目录
hadoop.namespace: /data

spring:
    datasource:
        driverClassName: com.mysql.cj.jdbc.Driver
        url: jdbc:mysql://localhost:3306/springbootnd27788u?useUnicode=true&characterEncoding=utf-8&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=GMT%2B8&useSSL=false
        username: root
        password: Zu123456Le

    servlet:
      multipart:
        max-file-size: 300MB
        max-request-size: 300MB
    resources:
      static-locations: classpath:static/,file:static/

hive:
  url: jdbc:hive2://127.0.0.1:10000/default
  driver-class-name: org.apache.hive.jdbc.HiveDriver
  type: com.alibaba.druid.pool.DruidDataSource
  user: root
  password: 123456
  
  # 下面为连接池的补充设置，应用到上面所有数据源中
  # 初始化大小，最小，最大
  initialSize: 1
  minIdle: 3
  maxActive: 20
  # 配置获取连接等待超时的时间
  maxWait: 60000
  # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
  timeBetweenEvictionRunsMillis: 60000
  # 配置一个连接在池中最小生存的时间，单位是毫秒
  minEvictableIdleTimeMillis: 30000
  validationQuery: select 1
  testWhileIdle: true
  testOnBorrow: false
  testOnReturn: false
  # 打开PSCache，并且指定每个连接上PSCache的大小
  poolPreparedStatements: true
  maxPoolPreparedStatementPerConnectionSize: 20